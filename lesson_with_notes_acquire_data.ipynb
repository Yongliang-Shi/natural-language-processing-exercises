{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Data through Web Scraping\n",
    "When the data you need is not accessible through CSVs, APIs, SQL, or other types, there is an option. This option is known as web scraping.\n",
    "\n",
    "**Web Scraping Ethics**\n",
    "Make sure the website's terms of use allow for web scraping. You can generally find a terms of service page, or take a look at `example.com/robots.txt` to find the policy for computers looking at the web site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, we'll go about web scraping through this process:\n",
    "\n",
    "1. Manually explore the site in a web browser, and identify the relevant HTML elements.\n",
    "2. Use the requests module to obtain the HTML from the page.\n",
    "3. Use BeautifulSoup to parse the HTML and obtain the text/data that we want.\n",
    "4. (Maybe) Script the process of requesting another page and parsing the data from it as well.\n",
    "5. Take this data further down the data science pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Import the get() function from the requests module, BeautifulSoup from bs4, and pandas.\n",
    "2. Assign the address of the web page to a variable named url.\n",
    "3. Request the server the content of the web page by using get(), and store the server’s response in the variable response.\n",
    "4. Print the response text to ensure you have an html page.\n",
    "5. Take a look at the actual web page contents and inspect the source to understand the structure a bit.\n",
    "6. Use BeautifulSoup to parse the HTML into a variable ('soup').\n",
    "7. Identify the key tags you need to extract the data you are looking for.\n",
    "8. Create a dataframe of the data desired.\n",
    "9. Run some summary stats and inspect the data to ensure you have what you wanted.\n",
    "10. Edit the data structure as needed, especially so that one column has all the text you want included in this analysis.\n",
    "11. Create a corpus of the column with the text you want to analyze.\n",
    "12. Store that corpus for use in a future notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Import the get( ) function from the requests module, BeautifulSoup from bs4, and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson, we'll take a look at an article from Codeup's blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Assign the address of the web page to a variable named url.\n",
    "#### Step 3. Request the server content of the web page by using get( ), and store the server's response in the variable response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to hold the web address\n",
    "\n",
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "\n",
    "# Some websites don't accept the pyhon-requests default user-agent\n",
    "headers = {'User-Agent': 'Codeup Data Science'} \n",
    "\n",
    "# Get the response\n",
    "response = get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Print the response text to ensure you have an html page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en-US\"><head >\t<meta charset=\"UTF-8\" />\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "\t\n",
      "\t<!-- This site is optimized with the Yoast SEO plugin v15.2 - https://yoast.com/wordpress/plugins/seo/ -->\n",
      "\t<title>Codeup’s Data Science Career Accelerator is Here! - Codeup</title>\n",
      "\t<meta name=\"description\" content=\"The rumors are true! The time has arrived\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a look at the actual web page contents and inspect the source to understand the structure a bit.\n",
    "\n",
    "As we see from the first line of the response, the server sent us an **HTML document**. This document describes the overall structure of that web page, along with its specific content (which is what makes that particular page unique).\n",
    "\n",
    "For the most part, all of the pages from a single website will have the same (or very similar) overall structure. **To write our script, we will need to understand the HTML structure of one page**, and we will use the browser’s Developer Tools to do that.\n",
    "- `command + option + u` will let you view the source of a page in chrome.\n",
    "- `command + option + i` will open up the chrome dev tools page inspector.\n",
    "- Right clicking on specific text in the page and selecting 'inspect' will take you right to the html of that text\n",
    "    \n",
    "In general, we'll be looking for **HTML tags**, and using a couple properties of those tags to identify the content that we want. Two element properties are important to us:\n",
    "- `class`: This is a list of the class(es) that are applied to an element, these can be used to target certain elements, but are not guaranteed to be unique.\n",
    "- `id`: This is a unique identifier for an element on a page.\n",
    "\n",
    "We'll use the beautiful soup library to work with HTML data in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Take a look at the actual web page contents and inspect the source to understand the structure a bit.\n",
    "#### 6. Use BeautifulSoup to parse the HTML into a variable ('soup')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a soup variable holding the response content\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup Methods and Properties\n",
    "\n",
    "- `soup.title.string`: gets the page's title (the same text in the browser tab for a page, this is the `title` element.\n",
    "    \n",
    "- `soup.prettify()`: is useful to print in case you want to see the HTML\n",
    "    \n",
    "- `soup.find_all(\"a\")`: find all the anchor tags, or whatever argument is specified.\n",
    "    \n",
    "- `soup.find(\"h1\")`: finds the first matching element\n",
    "    \n",
    "- `soup.get_text()`: gets the text from within a matching piece of soup/HTML\n",
    "    \n",
    "- The `soup.select()` method takes in a CSS selector as a string and returns all matching elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Idenfity the key tags you need to extract the data you are looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = soup.find('div', class_='jupiterx-post-content')\n",
    "article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some text to process, we can **store it for future use**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as f:\n",
    "    f.write(article.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now package all of our code up in a nice function that we can use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text():\n",
    "    # if we already have the data, read it locally\n",
    "    if path.exists('article.txt'):\n",
    "        with open('article.txt') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # otherwise go fetch the data\n",
    "    url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    article = soup.find('div', class_='jupiterx-post-content')\n",
    "\n",
    "    # save it for next time\n",
    "    with open('article.txt', 'w') as f:\n",
    "        f.write(article.text)\n",
    "\n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML and CSS Crash Course\n",
    "\n",
    "**HTML is the language for content and structure on the web.** This means that HTML **specifies what content is what: tex, images, links, tables, containers, etc...**\n",
    "\n",
    "**CSS is the language for styling and presentation.** This means CSS specifies color, background, texture, position, etc...\n",
    "\n",
    "### HTML Basics\n",
    "\n",
    "HTML consists of elements denoted by **tags**. These tags are contained in angle brackets like `<main>`. Notice how there are opening and closing tags that contain other elements.\n",
    "\n",
    "HTML tags nest inside of other HTML tags, just like directories and files are nested in other directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "        <title>This is the title of the page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <heading>\n",
    "            <h1>Welcome to the blog!</h1>\n",
    "            <p>Blog is short for \"back-log\"</p>\n",
    "        </heading>\n",
    "        <main>\n",
    "            <h2>Read your way to insight!</h2>\n",
    "            <section id=\"posts\">\n",
    "                <article class=\"blog_post\">\n",
    "                    <h3>Hello World</h3>\n",
    "                    <p>This is the first post!</p>\n",
    "                </article>\n",
    "                <article class=\"blog_post\">\n",
    "                    <h3>HTML Is Awesome</h3>\n",
    "                    <p>It's the language and structure for the web!</p>\n",
    "                </article>\n",
    "                <article class=\"blog_post\">\n",
    "                    <h3>CSS Is Totally Rad</h3>\n",
    "                    <p>CSS Selectors are super powerful</p>\n",
    "                </article>\n",
    "            </section>\n",
    "        </main>\n",
    "        <footer>\n",
    "            <p>All rights reserved.</p>\n",
    "        </footer>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS Selectors\n",
    "\n",
    "- The name of the element itself is a selector. For example `soup.select(\"p\")` will select every paragraph tag and `soup.select(\"footer\")` selects the footer element (and everything inside it)\n",
    "\n",
    "- The id selector is denoted with a `#`. For example `soup.select(\"#posts\")` will return the html element noted with the `id=posts` attribute\n",
    "\n",
    "- The class selector is denoted with a `.` symbol before the class name. For example, `soup.select(\".blog_post\")` returns all of the elements that have that class name."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
